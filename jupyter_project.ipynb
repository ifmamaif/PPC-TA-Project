{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "492ad080-1ec1-4268-96e0-f558125b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import cv2                         # pip install opencv-python\n",
    "import enchant                     # pip install pyenchant\n",
    "import numpy                       # pip install numpy\n",
    "from autocorrect import Speller    # pip install autocorrect\n",
    "from PIL import Image              # pip install Pillow\n",
    "\n",
    "import pytesseract                 # pip install pytesseract (remember that you need to install tesseract-ocr-w64-setup-5.3.0.20221222) \n",
    "import pdf2image                   # pip install pdf2image   (remember that you need to install poppler, you use have the binary/exe inside folder instaslls)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "88216c58-f6ee-419c-8f87-2e49e71e7727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to binary/executable tesseract\n",
    "# If you don't have tesseract executable in your PATH, include the following:\n",
    "# Example tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract'\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'\n",
    "\n",
    "# Tesseract config\n",
    "# NOPE: 0,1,2,3,4,5,7,8,9,10,13\n",
    "# not enough : 6  Assume a single uniform block of text.                            (\"\"; \" YEP. MAKING FUN OF HIM IS\")\n",
    "# not enough : 12 Sparse text with OSD.                                             (\"Very\";\" OF HIM\")\n",
    "# doable :     11 Sparse text. Find as much text as possible in no particular order.(\"REALLY VERY\";\"MAKING FUN OF HIM IS\")\n",
    "teserract_custom_oem_psm_config = r'--oem 3 --psm 11'\n",
    "\n",
    "# path to binary/executable poppler (pdf2images)\n",
    "#popplerPath=r'C:\\ProgramData\\chocolatey\\lib\\poppler\\tools'\n",
    "popplerPath=r'installs\\poppler'\n",
    "\n",
    "# Spell Checker / Autocorrect\n",
    "spellChecker = Speller(lang='en')\n",
    "\n",
    "d = enchant.Dict(\"en_US\")\n",
    "d = enchant.Dict(\"en_US\")\n",
    "spell = Speller(lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "67f4b44e-5b7d-46d7-9e69-7d90732a84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PdfToImages('D:\\\\Cursuri\\\\Cognitive Computing\\\\t1.pdf')\n",
    "def PdfToImages(filePath):\n",
    "    pages = pdf2image.convert_from_path(filePath, 500,poppler_path=popplerPath)\n",
    "    print (pages)\n",
    "    for i in range(len(pages)):\n",
    "        pages[i].save('page'+ str(i) +'.jpg', 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7d7e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image by removing a number of pixels\n",
    "def shrinkByPixels(im, pixels):\n",
    "    h = im.shape[0]\n",
    "    w = im.shape[1] \n",
    "    return im[pixels:h-pixels, pixels:w-pixels]\n",
    "\n",
    "# Adjust the gamma in an image by some factor\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "   invGamma = 1.0 / gamma\n",
    "   table = numpy.array([((i / 255.0) ** invGamma) * 255\n",
    "      for i in numpy.arange(0, 256)]).astype(\"uint8\")\n",
    "   return cv2.LUT(image, table)\n",
    "\n",
    "# Comparison function for sorting contours\n",
    "def get_contour_precedence(contour, cols):\n",
    "    tolerance_factor = 200\n",
    "    origin = cv2.boundingRect(contour)\n",
    "    return ((origin[1] // tolerance_factor) * tolerance_factor) * cols + origin[0]\n",
    "\n",
    "# Find all speech bubbles in the given comic page and return a list of their contours\n",
    "def findSpeechBubbles(image):\n",
    "    # Convert image to gray scale\n",
    "    imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Recognizes rectangular/circular bubbles, struggles with dark colored bubbles \n",
    "    binary = cv2.threshold(imageGray,235,255,cv2.THRESH_BINARY)[1]\n",
    "    # Find contours and document their heirarchy for later\n",
    "    contours, hierarchy = cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contourMap = {}\n",
    "    finalContourList = []\n",
    "\n",
    "    contourMap = filterContoursBySize(contours)\n",
    "    contourMap = filterContainingContours(contourMap, hierarchy)\n",
    "\n",
    "    # Sort final contour list\n",
    "    finalContourList = list(contourMap.values())\n",
    "    finalContourList.sort(key=lambda x:get_contour_precedence(x, binary.shape[1]))\n",
    "\n",
    "    return finalContourList\n",
    "\n",
    "def filterContoursBySize(contours):\n",
    "    for i in range(len(contours)): \n",
    "        if cv2.contourArea(contours[i]) > 1000:\n",
    "            print(cv2.contourArea(contours[i]))\n",
    "    \n",
    "    # We could pass this in and update it by reference, but I prefer this sort of 'immutable' handling.\n",
    "    contourMap = {}\n",
    "    for i in range(len(contours)):\n",
    "        # Filter out speech bubble candidates with unreasonable size\n",
    "        if cv2.contourArea(contours[i]) < 120000 and cv2.contourArea(contours[i]) > 4000:#4000\n",
    "            # Smooth out contours that were found\n",
    "            epsilon = 0.0025*cv2.arcLength(contours[i], True)\n",
    "            approximatedContour = cv2.approxPolyDP(contours[i], epsilon, True)\n",
    "            contourMap[i] = approximatedContour\n",
    "\n",
    "    return contourMap\n",
    "\n",
    "# Sometimes the contour algorithm identifies entire panels, which can contain speech bubbles already\n",
    "#  identified causing us to parse them twice via OCR. This method attempts to remove contours that \n",
    "#  contain other speech bubble candidate contours completely inside of them.\n",
    "def filterContainingContours(contourMap, hierarchy):\n",
    "    # I really wish there was a better way to do this than this O(n^2) removal of all parents in\n",
    "    #  the heirarchy of a contour, but with the number of contours found this is the only way I can\n",
    "    #  think of to do this.\n",
    "    for i in list(contourMap.keys()):\n",
    "        currentIndex = i\n",
    "        while hierarchy[0][currentIndex][3] > 0:\n",
    "            if hierarchy[0][currentIndex][3] in contourMap.keys():\n",
    "                contourMap.pop(hierarchy[0][currentIndex][3])\n",
    "            currentIndex = hierarchy[0][currentIndex][3]\n",
    "\n",
    "    # I'd prefer to handle this 'immutably' like above, but I'd rather not make an unnecessary copy of the dict.\n",
    "    return contourMap\n",
    "\n",
    "# Given a list of contours, return a list of cropped images based on the bounding rectangles of the contours\n",
    "def cropSpeechBubbles(image, contours, padding = 0):\n",
    "    croppedImageList = []\n",
    "    for contour in contours:\n",
    "        rect = cv2.boundingRect(contour)\n",
    "        [x, y, w, h] = rect\n",
    "        croppedImage = image[y-padding:y+h+padding, x-padding:x+w+padding]\n",
    "        croppedImageList.append(croppedImage)\n",
    "    return croppedImageList\n",
    "\n",
    "# Process a line of text based on some \"business\" rules\n",
    "def processScript(script):\n",
    "    # Some modern comics have this string on their cover page\n",
    "    if \"COMICS.COM\" in script:\n",
    "        return ''\n",
    "\n",
    "    # Tesseract sometimes picks up 'I' chars as '|'\n",
    "    script = script.replace('|','I')\n",
    "    # We want new lines to be spaces so we can treat each speech bubble as one line of text\n",
    "    script = script.replace('\\n',' ')\n",
    "    # Remove multiple spaces from our string\n",
    "    words = script.split()\n",
    "    script = ' '.join(words)\n",
    "\n",
    "    for char in script:\n",
    "        # Comic books tend to be written in upper case, so we remove anything other than upper case chars\n",
    "        if char not in ' -QWERTYUIOPASDFGHJKLZXCVBNM,.?!\"\"\\'â€™1234567890':\n",
    "            script = script.replace(char,'')\n",
    "\n",
    "    # This line removes \"- \" and concatenates words split on two lines\n",
    "    #  One notable edge case we don't handle here, hyphenated words split on two lines\n",
    "    script = re.sub(r\"(?<!-)- \", \"\", script)\n",
    "    words = script.split()\n",
    "    for i in range(0, len(words)):\n",
    "        # Spellcheck all words\n",
    "        if not d.check(words[i]):\n",
    "            alphaWord = ''.join([j for j in words[i] if j.isalpha()])\n",
    "            if alphaWord and not d.check(alphaWord):\n",
    "                words[i]=spell(words[i].lower()).upper()\n",
    "        # Remove single chars other than 'I' and 'A'\n",
    "        if len(words[i]) == 1:\n",
    "            if (words[i] != 'I' and words[i] != 'A'):\n",
    "                words[i] = ''\n",
    "\n",
    "    # Remove any duplicated spaces\n",
    "    script = ' '.join(words)\n",
    "    words = script.split()\n",
    "    final = ' '.join(words)\n",
    "\n",
    "    # Remove all two char lines other than 'NO' and 'OK'\n",
    "    if len(final) == 2 and script != \"NO\" and script != \"OK\":\n",
    "        return ''\n",
    "\n",
    "    return final\n",
    "\n",
    "# Apply the ocr engine to the given image and return the recognized script where illegitimate characters are filtered out\n",
    "def tesseract(image):\n",
    "    # We could consider using tessedit_char_whitelist to limit the recognition of Tesseract. \n",
    "    #   Doing that degraded OCR performance in practice\n",
    "    script = pytesseract.image_to_string(image, lang = 'eng',config=teserract_custom_oem_psm_config)\n",
    "    #return (script)\n",
    "    return processScript(script)\n",
    "\n",
    "def segmentPage(image, shouldShowImage = False):\n",
    "    contours = findSpeechBubbles(image)\n",
    "    croppedImageList = cropSpeechBubbles(image, contours)\n",
    "\n",
    "    cv2.drawContours(image, contours, -1, (255, 0, 0), 2)\n",
    "    if shouldShowImage:\n",
    "        cv2.imshow('Speech Bubble Identification', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return croppedImageList\n",
    "\n",
    "def parseComicSpeechBubbles(croppedImageList, shouldShowImage = False):\n",
    "    scriptList = []\n",
    "\n",
    "    for croppedImage in croppedImageList:\n",
    "        # Enlarge cropped image\n",
    "        croppedImage = cv2.resize(croppedImage, (0,0), fx = 2, fy = 2)\n",
    "        # # Denoise\n",
    "        croppedImage = cv2.fastNlMeansDenoisingColored(croppedImage, None, 10, 10, 7, 15)\n",
    "\n",
    "        if shouldShowImage:\n",
    "            cv2.imshow('Cropped Speech Bubble', croppedImage)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "        # Pass cropped image to the ocr engine\n",
    "        script = tesseract(croppedImage)\n",
    "       \n",
    "        # If we don't find any characters, try shrinking the cropped area. \n",
    "        #  This occasionally helps tesseract recognize single word lines, but increases processing time.\n",
    "        count = 0\n",
    "        while (script == '' and count < 3):\n",
    "            count+=1\n",
    "            croppedImage = shrinkByPixels(croppedImage, 5)\n",
    "            script = tesseract(croppedImage)\n",
    "\n",
    "        if script != '' and script not in scriptList:\n",
    "            scriptList.append(script)\n",
    "            print(\"\\ndada  \" +script+\"\\n\")\n",
    "\n",
    "    return scriptList\n",
    "\n",
    "def apprun(filePath, showImages=False):\n",
    "    file = open(filePath, \"r\")\n",
    "    img = cv2.imread(filePath)\n",
    "    croppedImageList = segmentPage(img, showImages)\n",
    "    pageText = parseComicSpeechBubbles(croppedImageList,showImages)\n",
    "    return pageText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b8f632-d35e-431d-ab59-081298e7a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281248.0\n",
      "26703.0\n",
      "1653.0\n",
      "4342.0\n",
      "3022.5\n",
      "36037.5\n",
      "73511.5\n",
      "18983.0\n",
      "17295.0\n",
      "12627.5\n",
      "189992.5\n",
      "31873.5\n",
      "29491.5\n",
      "193358.0\n"
     ]
    }
   ],
   "source": [
    "apprun('images\\\\t1.png', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7154126c-7452-46ea-a9df-1fdaaeb9e3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ee9f22-1072-4f76-b9a5-aeabc1a099f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
